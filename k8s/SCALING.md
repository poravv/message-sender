# OptimizaciÃ³n de Recursos - KEDA Auto-Scaling

## ğŸ“Š ConfiguraciÃ³n Actual

### Recursos del Pod
- **CPU Request**: 100m (0.1 cores)
- **CPU Limit**: 300m (0.3 cores)
- **Memory Request**: 256Mi
- **Memory Limit**: 512Mi
- **Ephemeral Storage**: 512Mi - 1Gi

### Auto-Scaling
- **Min Replicas**: 0 (se duerme cuando no hay trÃ¡fico)
- **Max Replicas**: 2
- **Cooldown**: 5 minutos sin trÃ¡fico para escalar a 0
- **Scale Up**: ActivaciÃ³n inmediata en trÃ¡fico

## ğŸ¯ Triggers de Escalado

1. **CPU > 70%** â†’ Escala UP
2. **Memory > 80%** â†’ Escala UP
3. **HTTP Requests > 5/seg** â†’ Escala UP
4. **Sin trÃ¡fico por 5 min** â†’ Escala a 0

## ğŸš€ InstalaciÃ³n de KEDA (Opcional)

Si quieres usar scale-to-zero con KEDA:

```bash
# Instalar KEDA en el cluster
kubectl apply --server-side -f https://github.com/kedacore/keda/releases/download/v2.12.0/keda-2.12.0.yaml

# Verificar instalaciÃ³n
kubectl get pods -n keda

# Aplicar ScaledObject
kubectl apply -f k8s/keda-scaledobject.yaml
```

## ğŸ“ˆ Monitoreo

```bash
# Ver estado del HPA
kubectl get hpa -n sender

# Ver eventos de escalado
kubectl describe hpa sender-backend-hpa -n sender

# Ver rÃ©plicas actuales
kubectl get deployment sender-backend -n sender

# Si KEDA estÃ¡ instalado
kubectl get scaledobject -n sender
kubectl describe scaledobject sender-backend-scaledobject -n sender
```

## ğŸ’° Ahorro de Recursos

### Sin TrÃ¡fico (0 rÃ©plicas)
- **CPU**: 0m
- **Memory**: 0Mi
- **Ahorro**: 100%

### Con TrÃ¡fico Bajo (1 rÃ©plica)
- **CPU**: ~50-100m
- **Memory**: ~200-300Mi
- **Ahorro**: ~80% vs configuraciÃ³n anterior (500m CPU, 1.5Gi RAM)

### Con TrÃ¡fico Alto (2 rÃ©plicas)
- **CPU**: ~200m
- **Memory**: ~500Mi
- **Ahorro**: ~60% vs configuraciÃ³n anterior

## âš™ï¸ ConfiguraciÃ³n Manual

Si no usas KEDA, el HPA tradicional mantiene **mÃ­nimo 1 rÃ©plica**.

Para forzar 0 rÃ©plicas manualmente:
```bash
kubectl scale deployment sender-backend -n sender --replicas=0
```

Para reactivar:
```bash
kubectl scale deployment sender-backend -n sender --replicas=1
```

## ğŸ”§ Troubleshooting

### El pod no escala a 0
1. Verificar que KEDA estÃ© instalado: `kubectl get pods -n keda`
2. Revisar mÃ©tricas: `kubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes`
3. Ver logs de KEDA: `kubectl logs -n keda -l app=keda-operator`

### Tarda mucho en despertar
- Kubernetes puede tardar 10-30 segundos en levantar el pod desde 0
- El usuario verÃ¡ un timeout inicial, luego funcionarÃ¡ normal
- Considera mantener minReplicas: 1 si necesitas respuesta inmediata

## ğŸ“ Notas

- **KEDA es opcional**: Si no estÃ¡ instalado, usa HPA tradicional con min=1
- **Cold Start**: ~15-30 seg para levantar desde 0 rÃ©plicas
- **Redis/MinIO**: No afectados, siempre activos
- **Sesiones WhatsApp**: Persisten en Redis, se reconectan automÃ¡ticamente
